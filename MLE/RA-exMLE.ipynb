{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE of Normal distribution\n",
    "* Let $X \\sim N(\\mu, \\sigma^2)$. \n",
    "    * Estimator vector $\\bold{\\theta} = (\\mu, \\sigma)$, Random samples $X_1, X_2, ...,X_n$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Likelihood Function\n",
    "* Likelihood function = Joint distribution of random samples $X_1, X_2, ... , X_n$\n",
    "$$ L(\\mu, \\sigma) = f(x_1, x_2, ...,x_n) = \\Pi^{n}_{i=1}f(x_i;\\theta)  $$\n",
    "\n",
    "* Log Likelihood function\n",
    "$$ logL(\\mu, \\sigma) = l(\\mu, \\sigma)= -\\frac{n}{2}log2\\pi-nlog\\sigma-\\frac{1}{2}\\sum^n_{i=1}(\\frac{x_i-\\mu}{\\sigma})^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the negative log-likelihood function for a normal distribution\n",
    "def neg_log_likelihood(params, data):\n",
    "    mu, sigma = params\n",
    "    n = len(data)\n",
    "    return (n/2) * np.log(2*np.pi*sigma**2) + (1/(2*sigma**2)) * np.sum((data - mu)**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Sampling\n",
    "* Generate a sample dataset from normal distribution (``np.random.normal(mu, sigma, size)``)\n",
    "* Define initial parameter values (``initial_params``) for optimization. These values serve as a starting point for the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sample dataset\n",
    "data = np.random.normal(5, 2, 100) # X ~ N(5, 4)\n",
    "\n",
    "# define the initial parameter values for optimization\n",
    "initial_params = [0, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find MLE \n",
    "* Using the ``minimize()`` function from the ``scipy.optimize`` module, we minimize the negative log-likelihood function to find the maximum likelihood estimates (MLE) for the parameters.\n",
    "* ``scipy.optimize.minimize(fun, x0, args=(), method=None, ...)``\n",
    "    * fun: The objective function to be minimized. It should take the variables to be optimized as input and return the value of the function to be minimized.\n",
    "    * x0: The initial guess or starting point for the optimization. It can be a scalar or an array-like object.\n",
    "    * args: Additional arguments to be passed to the objective function fun.\n",
    "    * method: The optimization algorithm to be used. It can be specified as a string or an OptimizeResult object. If not specified, the default algorithm is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize the negative log-likelihood function to find MLE\n",
    "result = minimize(neg_log_likelihood, initial_params, args=(data,))\n",
    "mu_mle, sigma_mle = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated MLE - mu: 4.792306853229411\n",
      "Estimated MLE - sigma: 1.8072323306279252\n"
     ]
    }
   ],
   "source": [
    "# print the estimated MLE\n",
    "print(\"Estimated MLE - mu:\", mu_mle) # True mu: 5\n",
    "print(\"Estimated MLE - sigma:\", sigma_mle) # True sigma: 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE for Linear Regression Model \n",
    "* Let $Y_i = \\alpha + \\beta(x_i -\\bar{x}) + e_i$ where $\\bar{x} = \\frac{1}{n} \\sum^{n}_{i=1}x_i$ and $e_i \\sim^{iid} N(0, \\sigma^2)$\n",
    "    * Estimator vector $\\bold{\\theta} = (\\alpha, \\beta, \\sigma)$, Random samples $X_1, X_2, ...,X_n$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate data using Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define linear regression model function\n",
    "def reg(params, data):\n",
    "    alpha, beta, sigma = params\n",
    "    n = len(data)\n",
    "    \n",
    "    x_bar = np.mean(data)\n",
    "    epsilon = np.random.normal(0, sigma, n)\n",
    "    \n",
    "    return alpha + beta*(data-x_bar) + epsilon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sample dataset (x, y) using linear regression\n",
    "x = np.random.randn(100) \n",
    "true_params = [2, 3, 1]\n",
    "y = reg(true_params, x) # yi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Likelihood Function\n",
    "* Negative Log Likelihood function\n",
    "$$ -logL(\\alpha, \\beta, \\sigma) = \\frac{n}{2} log(2\\pi\\sigma^2) + \\frac{\\sum^n_{i=1}[y_i-\\alpha-\\beta(x_i-\\bar{x})]^2}{2\\sigma^2} $$\n",
    "\n",
    "* cf. Line-point vertical distance function (Residual)\n",
    "$$H(\\alpha, \\beta) = \\sum^n_{i=1}[y_i-\\alpha-\\beta(x_i-\\bar{x})]^2 = \\sum^n_{i=1} (y_i-\\hat{y_i})^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the negative log-likelihood function for linear regression\n",
    "def neg_log_likelihood(params, x, y):\n",
    "    alpha, beta, sigma = params \n",
    "    x_bar = np.mean(x)\n",
    "    n = len(x)\n",
    "    \n",
    "    y_pred = alpha + beta * (x - x_bar) # yhat; no epsilon term \n",
    "    residuals = y - y_pred\n",
    "    \n",
    "    return (n/2 * np.log(2*np.pi*sigma**2)) + (np.sum(residuals**2) / 2*sigma**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find MLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the initial parameter values for optimization\n",
    "initial_params = [0, 0, 1]  # initial values for alpha, beta, and sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize the negative log-likelihood function\n",
    "result = minimize(neg_log_likelihood, initial_params, args=(x, y))\n",
    "alpha_mle, beta_mle, sigma_mle = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated MLE - alpha: 1.8740702012081738\n",
      "Estimated MLE - beta: 2.632050426560142\n",
      "Estimated MLE - sigma: -0.949647150130543\n"
     ]
    }
   ],
   "source": [
    "# print the estimated MLEs\n",
    "print(\"Estimated MLE - alpha:\", alpha_mle) # True alpha: 2\n",
    "print(\"Estimated MLE - beta:\", beta_mle) # True beta: 3\n",
    "print(\"Estimated MLE - sigma:\", sigma_mle) # True sigma: 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE for Bivariate Normal Distribution\n",
    "\n",
    "* Starting from the most basic model $\\boldsymbol{Z} = \\{Z_1, Z_2\\}'$, where $Z_1, Z_2$ independent, and follow $N(0, 1)$\n",
    "    * $\\boldsymbol{Z} \\sim N(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) = N(\\{\\mu_1,\\mu_2\\}', \\begin{pmatrix} Var(Z_1) & Cov(Z_1, Z_2) \\\\ Cov(Z_2, Z_1) & Var(Z_2) \\end{pmatrix}) = N(\\{0,0\\}', \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix})$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate data from Bivariate normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000 # number of data points\n",
    "N = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_true = np.array([0, 0])\n",
    "sigma_true = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "data = np.random.multivariate_normal(mu_true, sigma_true, size=n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_matrix_properties(matrix):\n",
    "    # check if the matrix is symmetric\n",
    "    is_symmetric = np.allclose(matrix, matrix.T)\n",
    "    \n",
    "    # check if the matrix is positive semi-definite\n",
    "    eigenvalues = np.linalg.eigvals(matrix)\n",
    "    is_positive_semidef = np.all(eigenvalues >= 0)\n",
    "    \n",
    "    # check if the matrix is invertible\n",
    "    is_invertible = np.linalg.matrix_rank(matrix) == matrix.shape[0]\n",
    "    \n",
    "    return is_symmetric, is_positive_semidef, is_invertible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is symmetric: True\n",
      "Is positive semi-definite: True\n",
      "Is invertible: True\n"
     ]
    }
   ],
   "source": [
    "is_symmetric, is_positive_semidef, is_invertible = check_matrix_properties(sigma_true)\n",
    "print(\"Is symmetric:\", is_symmetric)\n",
    "print(\"Is positive semi-definite:\", is_positive_semidef)\n",
    "print(\"Is invertible:\", is_invertible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.54066973,  0.8305306 ])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[initial_params[N], initial_params[-1]], [initial_params[-1], initial_params[N+1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the log-likelihood function for the multivariate normal distribution\n",
    "def log_likelihood(params, data):\n",
    "    mu = np.array(params[:N]) # [1.0, 2.0]\n",
    "    Sigma = np.array([[params[N]**1, params[-1]], [params[-1], params[N+1]**1]])\n",
    "    n = len(data)\n",
    "    \n",
    "    inv_Sigma = np.linalg.inv(Sigma)\n",
    "    log_det_Sigma = np.log(np.linalg.det(Sigma))\n",
    "    \n",
    "    logL = 0.0\n",
    "    for i in range(n):\n",
    "        x = data[i]\n",
    "        logL += -0.5 * (x - mu) @ inv_Sigma @ (x - mu).T - 0.5 * log_det_Sigma\n",
    "    return -logL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize the mean vector and covariance matrix\n",
    "# mu_initial = np.array([1.0, 2.0])\n",
    "# sigma_initial = np.array([[1.0, 0.0], [0.0, 1.0]])\n",
    "\n",
    "true_params = [0,0,1,1,0]\n",
    "initial_params = true_params\n",
    "# initial_params = [1.0, 2.0, 1.0, 1.0, 0.0]\n",
    "\n",
    "# combine the mean vector and covariance matrix\n",
    "# initial_params = np.concatenate((mu_initial, sigma_initial.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is symmetric: True\n",
      "Is positive semi-definite: True\n",
      "Is invertible: True\n"
     ]
    }
   ],
   "source": [
    "is_symmetric, is_positive_semidef, is_invertible = check_matrix_properties(sigma_params)\n",
    "print(\"Is symmetric:\", is_symmetric)\n",
    "print(\"Is positive semi-definite:\", is_positive_semidef)\n",
    "print(\"Is invertible:\", is_invertible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize the negative log-likelihood to estimate the parameters\n",
    "result = minimize(log_likelihood, initial_params, args=(data,))\n",
    "estimated_params = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00734159, -0.01058431,  0.99620288,  1.00486874, -0.01024977])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3 into shape (2,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[200], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# extract the estimated mean and covariance matrix\u001b[39;00m\n\u001b[1;32m      2\u001b[0m estimated_mean \u001b[39m=\u001b[39m estimated_params[:N]\n\u001b[0;32m----> 3\u001b[0m estimated_cov \u001b[39m=\u001b[39m estimated_params[N:]\u001b[39m.\u001b[39;49mreshape((N, N))\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEstimated mean:\u001b[39m\u001b[39m\"\u001b[39m, estimated_mean)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEstimated covariance matrix:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3 into shape (2,2)"
     ]
    }
   ],
   "source": [
    "# extract the estimated mean and covariance matrix\n",
    "estimated_mean = estimated_params[:N]\n",
    "estimated_cov = estimated_params[N:].reshape((N, N))\n",
    "\n",
    "print(\"Estimated mean:\", estimated_mean)\n",
    "print(\"Estimated covariance matrix:\")\n",
    "print(estimated_cov)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE for Multivariate Normal Distribution\n",
    "\n",
    "* Let $\\boldsymbol{X} \\sim N(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$\n",
    "* N: size of dimension, n: number of data points\n",
    "    * $\\boldsymbol{\\mu}$: n 1 $\\times$ N vector = (1, N) array\n",
    "    * $\\boldsymbol{\\sigma}$: n N $\\times$ N matrix = (N, N) array\n",
    "    * Random vector $\\bold{X} = \\{X_1, X_2, ...,X_n\\}'$ where $X_i \\sim^{iid} N(\\mu, \\Sigma)$:  n 1 $\\times$ N vector = (n, 1, N) array\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate data from Multivariate normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2 # size of dimension\n",
    "n = 100  # number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_covariance_matrix(N):\n",
    "    # generate random matrix of size N by N\n",
    "    random_matrix = np.random.rand(N, N)\n",
    "    # create a symmetric covariance matrix\n",
    "    covariance_matrix = np.dot(random_matrix, random_matrix.T)\n",
    "    return covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_true = np.array([0., 1.])\n",
    "Sigma_true = generate_covariance_matrix(N)\n",
    "\n",
    "data = np.random.multivariate_normal(mu_true, Sigma_true, size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape # (n, N)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Likelihood Function\n",
    "* Log Likelihood function\n",
    "$$ logL(\\boldsymbol {\\mu}, \\boldsymbol {\\Sigma})= l(\\boldsymbol {\\mu}, \\boldsymbol {\\Sigma}) = \\sum^n_{i=1} -\\frac{1}{2}(\\bold{x}_i-\\boldsymbol{\\mu})^T\\boldsymbol{\\Sigma}^{-1}(\\bold{x}_i-\\boldsymbol{\\mu})-{\\frac {1}{2}}log|{\\boldsymbol {\\Sigma }}|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the log-likelihood function for the multivariate normal distribution\n",
    "def log_likelihood(params, data):\n",
    "    mu = params[:N]\n",
    "    Sigma = params[N:].reshape((N, N))\n",
    "    n = len(data)\n",
    "    \n",
    "    inv_Sigma = np.linalg.inv(Sigma)\n",
    "    log_det_Sigma = np.log(np.linalg.det(Sigma))\n",
    "    \n",
    "    logL = 0.0\n",
    "    for i in range(n):\n",
    "        x = data[i]\n",
    "        logL += -0.5 * (x - mu).T @ inv_Sigma @ (x - mu) - 0.5 * log_det_Sigma\n",
    "    return -logL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the parameters\n",
    "mean_params = np.zeros(N)\n",
    "cov_params = np.eye(N).flatten()\n",
    "\n",
    "initial_params = np.concatenate((mean_params, cov_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/pmjpggzn2yqbzlw4r8fbvcsm0000gn/T/ipykernel_85249/1427696438.py:8: RuntimeWarning: invalid value encountered in log\n",
      "  log_det_Sigma = np.log(np.linalg.det(Sigma))\n",
      "/var/folders/q0/pmjpggzn2yqbzlw4r8fbvcsm0000gn/T/ipykernel_85249/1427696438.py:8: RuntimeWarning: invalid value encountered in log\n",
      "  log_det_Sigma = np.log(np.linalg.det(Sigma))\n",
      "/var/folders/q0/pmjpggzn2yqbzlw4r8fbvcsm0000gn/T/ipykernel_85249/1427696438.py:8: RuntimeWarning: invalid value encountered in log\n",
      "  log_det_Sigma = np.log(np.linalg.det(Sigma))\n"
     ]
    }
   ],
   "source": [
    "# minimize the negative log-likelihood to estimate the parameters\n",
    "result = minimize(log_likelihood, initial_params, args=(data,))\n",
    "estimated_params = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean: [-501.60599538 1047.45045075]\n",
      "Estimated covariance matrix:\n",
      "[[ -893.94250711  1619.92624854]\n",
      " [ 1619.92632273 -1762.87581142]]\n"
     ]
    }
   ],
   "source": [
    "# extract the estimated mean and covariance matrix\n",
    "estimated_mean = estimated_params[:N]\n",
    "estimated_cov = estimated_params[N:].reshape((N, N))\n",
    "\n",
    "print(\"Estimated mean:\", estimated_mean)\n",
    "print(\"Estimated covariance matrix:\")\n",
    "print(estimated_cov)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SARvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
