{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE of Normal distribution\n",
    "* Let $X \\sim N(\\mu, \\sigma^2)$. \n",
    "    * Estimator vector $\\bold{\\theta} = (\\mu, \\sigma)$, Random samples $X_1, X_2, ...,X_n$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Likelihood Function\n",
    "* Likelihood function = Joint distribution of random samples $X_1, X_2, ... , X_n$\n",
    "$$ L(\\mu, \\sigma) = f(x_1, x_2, ...,x_n) = \\Pi^{n}_{i=1}f(x_i;\\theta)  $$\n",
    "\n",
    "* Log Likelihood function\n",
    "$$ logL(\\mu, \\sigma) = l(\\mu, \\sigma)= -\\frac{n}{2}log2\\pi-nlog\\sigma-\\frac{1}{2}\\sum^n_{i=1}(\\frac{x_i-\\mu}{\\sigma})^2  \\\\ = \n",
    "-\\frac{n}{2}(log(2\\pi\\sigma^2)) -\\frac{1}{2\\sigma^2}\\sum^n_{i=1}(x_i-\\mu)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the negative log-likelihood function for a normal distribution\n",
    "def neg_log_likelihood(params, data):\n",
    "    mu, sigma = params\n",
    "    n = len(data)\n",
    "    logL = -(n/2)*(np.log(2*np.pi*sigma**2)) - 1/(2*sigma**2) * np.sum((data-mu)**2)\n",
    "    return -logL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Sampling\n",
    "* Generate a sample dataset from normal distribution (``np.random.normal(mu, sigma, size)``)\n",
    "* Define initial parameter values (``initial_params``) for optimization. These values serve as a starting point for the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sample dataset\n",
    "data = np.random.normal(5, 2, 100) # X ~ N(5, 4)\n",
    "\n",
    "# define the initial parameter values for optimization\n",
    "initial_params = [0, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find MLE \n",
    "* Using the ``minimize()`` function from the ``scipy.optimize`` module, we minimize the negative log-likelihood function to find the maximum likelihood estimates (MLE) for the parameters.\n",
    "* ``scipy.optimize.minimize(fun, x0, args=(), method=None, ...)``\n",
    "    * fun: The objective function to be minimized. It should take the variables to be optimized as input and return the value of the function to be minimized.\n",
    "    * x0: The initial guess or starting point for the optimization. It can be a scalar or an array-like object.\n",
    "    * args: Additional arguments to be passed to the objective function fun.\n",
    "    * method: The optimization algorithm to be used. It can be specified as a string or an OptimizeResult object. If not specified, the default algorithm is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize the negative log-likelihood function to find MLE\n",
    "result = minimize(neg_log_likelihood, initial_params, args=(data,))\n",
    "mu_mle, sigma_mle = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated MLE - mu: 4.792306853229411\n",
      "Estimated MLE - sigma: 1.8072323306279252\n"
     ]
    }
   ],
   "source": [
    "# print the estimated MLE\n",
    "print(\"Estimated MLE - mu:\", mu_mle) # True mu: 5\n",
    "print(\"Estimated MLE - sigma:\", sigma_mle) # True sigma: 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE of Linear Regression Model \n",
    "* Let $Y_i = \\alpha + \\beta(x_i -\\bar{x}) + e_i$ where $\\bar{x} = \\frac{1}{n} \\sum^{n}_{i=1}x_i$ and $e_i \\sim^{iid} N(0, \\sigma^2)$\n",
    "    * Estimator vector $\\bold{\\theta} = (\\alpha, \\beta, \\sigma)$, Random samples $X_1, X_2, ...,X_n$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate data using Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define linear regression model function\n",
    "def reg(params, data):\n",
    "    alpha, beta, sigma = params\n",
    "    n = len(data)\n",
    "    \n",
    "    x_bar = np.mean(data)\n",
    "    epsilon = np.random.normal(0, sigma, n)\n",
    "    \n",
    "    return alpha + beta*(data-x_bar) + epsilon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sample dataset (x, y) using linear regression\n",
    "x = np.random.randn(100) \n",
    "true_params = [2, 3, 1]\n",
    "y = reg(true_params, x) # yi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Likelihood Function\n",
    "* Negative Log Likelihood function\n",
    "$$ -logL(\\alpha, \\beta, \\sigma) = \\frac{n}{2} log(2\\pi\\sigma^2) + \\frac{\\sum^n_{i=1}[y_i-\\alpha-\\beta(x_i-\\bar{x})]^2}{2\\sigma^2} $$\n",
    "\n",
    "* cf. Line-point vertical distance function (Residual)\n",
    "$$H(\\alpha, \\beta) = \\sum^n_{i=1}[y_i-\\alpha-\\beta(x_i-\\bar{x})]^2 = \\sum^n_{i=1} (y_i-\\hat{y_i})^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the negative log-likelihood function for linear regression\n",
    "def neg_log_likelihood(params, x, y):\n",
    "    alpha, beta, sigma = params \n",
    "    x_bar = np.mean(x)\n",
    "    n = len(x)\n",
    "    \n",
    "    y_pred = alpha + beta * (x - x_bar) # yhat; no epsilon term \n",
    "    residuals = y - y_pred\n",
    "    \n",
    "    return (n/2 * np.log(2*np.pi*sigma**2)) + (np.sum(residuals**2) / 2*sigma**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find MLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the initial parameter values for optimization\n",
    "initial_params = [0, 0, 1]  # initial values for alpha, beta, and sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize the negative log-likelihood function\n",
    "result = minimize(neg_log_likelihood, initial_params, args=(x, y))\n",
    "alpha_mle, beta_mle, sigma_mle = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated MLE - alpha: 1.8740702012081738\n",
      "Estimated MLE - beta: 2.632050426560142\n",
      "Estimated MLE - sigma: -0.949647150130543\n"
     ]
    }
   ],
   "source": [
    "# print the estimated MLEs\n",
    "print(\"Estimated MLE - alpha:\", alpha_mle) # True alpha: 2\n",
    "print(\"Estimated MLE - beta:\", beta_mle) # True beta: 3\n",
    "print(\"Estimated MLE - sigma:\", sigma_mle) # True sigma: 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE of Multivariate Normal Distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Likelihood function\n",
    "\n",
    "* Log Likelihood function\n",
    "$$ logL(\\boldsymbol {\\mu}, \\boldsymbol {\\Sigma})= l(\\boldsymbol {\\mu}, \\boldsymbol {\\Sigma}) = \\sum^n_{i=1} -\\frac{1}{2}(\\bold{x}_i-\\boldsymbol{\\mu})^T\\boldsymbol{\\Sigma}^{-1}(\\bold{x}_i-\\boldsymbol{\\mu})-{\\frac {1}{2}}log|{\\boldsymbol {\\Sigma }}|$$\n",
    "\n",
    "cf. $\\bold{x}_i-\\boldsymbol{\\mu}$ is a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the log-likelihood function for the bivariate normal distribution\n",
    "def log_likelihood(params, data):\n",
    "    k = data.shape[1] # dimension of random vector, 2\n",
    "    \n",
    "    mu = np.array(params[:k]) \n",
    "    Sigma = np.array([[params[k]**1, params[-1]], [params[-1], params[k+1]**1]])\n",
    "    n = len(data)\n",
    "    \n",
    "    inv_Sigma = np.linalg.inv(Sigma)\n",
    "    log_det_Sigma = np.log(np.linalg.det(Sigma))\n",
    "    \n",
    "    logL = 0.0\n",
    "    for i in range(n):\n",
    "        x = data[i]\n",
    "        logL += -0.5 * (x - mu) @ inv_Sigma @ (x - mu).T - 0.5 * log_det_Sigma\n",
    "    return -logL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000 # number of data points\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_true = np.array([0, 0])\n",
    "sigma_true = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "data = np.random.multivariate_normal(mu_true, sigma_true, size=n) # 2-dimensional array\n",
    "data.shape # [x1, x2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find MLE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_params = [0,0,1,1,0]\n",
    "initial_params = true_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize the negative log-likelihood to estimate the parameters\n",
    "result = minimize(log_likelihood, initial_params, args=(data,))\n",
    "estimated_params = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean: [-0.00535267 -0.01380805]\n",
      "Estimated covariance matrix:\n",
      "[[0.98280636 0.00593146]\n",
      " [0.00593146 0.00593146]]\n"
     ]
    }
   ],
   "source": [
    "# extract the estimated mean and covariance matrix\n",
    "estimated_mean = estimated_params[:k]\n",
    "estimated_cov = np.array([[estimated_params[k+1] , estimated_params[-1]], [estimated_params[-1] , estimated_params[k+2]]])\n",
    "\n",
    "print(\"Estimated mean:\", estimated_mean)\n",
    "print(\"Estimated covariance matrix:\")\n",
    "print(estimated_cov)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SARvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
