{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE of Normal distribution\n",
    "* Let $X \\sim N(\\mu, \\sigma^2)$. \n",
    "    * Estimator vector $\\bold{\\theta} = (\\mu, \\sigma)$, Random samples $X_1, X_2, ...,X_n$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Likelihood Function\n",
    "* Likelihood function = Joint distribution of random samples $X_1, X_2, ... , X_n$\n",
    "$$ L(\\mu, \\sigma) = f(x_1, x_2, ...,x_n) = \\Pi^{n}_{i=1}f(x_i;\\theta)  $$\n",
    "\n",
    "* Log Likelihood function\n",
    "$$ logL(\\mu, \\sigma) = l(\\mu, \\sigma)= -\\frac{n}{2}log2\\pi-nlog\\sigma-\\frac{1}{2}\\sum^n_{i=1}(\\frac{x_i-\\mu}{\\sigma})^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the negative log-likelihood function for a normal distribution\n",
    "def neg_log_likelihood(params, data):\n",
    "    mu, sigma = params\n",
    "    n = len(data)\n",
    "    return (n/2) * np.log(2*np.pi*sigma**2) + (1/(2*sigma**2)) * np.sum((data - mu)**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Sampling\n",
    "* Generate a sample dataset from normal distribution (``np.random.normal(mu, sigma, size)``)\n",
    "* Define initial parameter values (``initial_params``) for optimization. These values serve as a starting point for the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sample dataset\n",
    "data = np.random.normal(5, 2, 100) # X ~ N(5, 4)\n",
    "\n",
    "# define the initial parameter values for optimization\n",
    "initial_params = [0, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find MLE \n",
    "* Using the ``minimize()`` function from the ``scipy.optimize`` module, we minimize the negative log-likelihood function to find the maximum likelihood estimates (MLE) for the parameters.\n",
    "* ``scipy.optimize.minimize(fun, x0, args=(), method=None, ...)``\n",
    "    * fun: The objective function to be minimized. It should take the variables to be optimized as input and return the value of the function to be minimized.\n",
    "    * x0: The initial guess or starting point for the optimization. It can be a scalar or an array-like object.\n",
    "    * args: Additional arguments to be passed to the objective function fun.\n",
    "    * method: The optimization algorithm to be used. It can be specified as a string or an OptimizeResult object. If not specified, the default algorithm is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize the negative log-likelihood function to find MLE\n",
    "result = minimize(neg_log_likelihood, initial_params, args=(data,))\n",
    "mu_mle, sigma_mle = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated MLE - mu: 4.792306853229411\n",
      "Estimated MLE - sigma: -0.9085421409207677\n"
     ]
    }
   ],
   "source": [
    "# print the estimated MLE\n",
    "print(\"Estimated MLE - mu:\", mu_mle) # True mu: 5\n",
    "print(\"Estimated MLE - sigma:\", sigma_mle) # True sigma: 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE for Linear Regression Model \n",
    "* Let $Y_i = \\alpha + \\beta(x_i -\\bar{x}) + e_i$ where $\\bar{x} = \\frac{1}{n} \\sum^{n}_{i=1}x_i$ and $e_i \\sim^{iid} N(0, \\sigma^2)$\n",
    "    * Estimator vector $\\bold{\\theta} = (\\alpha, \\beta, \\sigma)$, Random samples $X_1, X_2, ...,X_n$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate data using Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define linear regression model function\n",
    "def reg(params, data):\n",
    "    alpha, beta, sigma = params\n",
    "    n = len(data)\n",
    "    \n",
    "    x_bar = np.mean(data)\n",
    "    epsilon = np.random.normal(0, sigma, n)\n",
    "    \n",
    "    return alpha + beta*(data-x_bar) + epsilon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sample dataset (x, y) using linear regression\n",
    "x = np.random.randn(100) \n",
    "true_params = [2, 3, 1]\n",
    "y = reg(true_params, x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Likelihood Function\n",
    "* Negative Log Likelihood function\n",
    "$$ -logL(\\alpha, \\beta, \\sigma) = \\frac{n}{2} log(2\\pi\\sigma^2) + \\frac{\\sum^n_{i=1}[y_i-\\alpha-\\beta(x_i-\\bar{x})]^2}{2\\sigma^2} $$\n",
    "\n",
    "* cf. Line-point vertical distance function (Residual)\n",
    "$$H(\\alpha, \\beta) = \\sum^n_{i=1}[y_i-\\alpha-\\beta(x_i-\\bar{x})]^2 = \\sum^n_{i=1} (y_i-\\hat{y_i})^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the negative log-likelihood function for linear regression\n",
    "def neg_log_likelihood(params, x, y):\n",
    "    alpha, beta, sigma = params \n",
    "    x_bar = np.mean(x)\n",
    "    n = len(x)\n",
    "    \n",
    "    y_pred = alpha + beta * (x - x_bar)\n",
    "    residuals = y - y_pred\n",
    "    \n",
    "    return (n/2 * np.log(2*np.pi*sigma**2)) + (np.sum(residuals**2) / 2*sigma**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find MLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the initial parameter values for optimization\n",
    "initial_params = [0, 0, 1]  # initial values for alpha, beta, and sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize the negative log-likelihood function\n",
    "result = minimize(neg_log_likelihood, initial_params, args=(x, y))\n",
    "alpha_mle, beta_mle, sigma_mle = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated MLE - alpha: 1.9501947724831497\n",
      "Estimated MLE - beta: 2.842505337191358\n",
      "Estimated MLE - sigma: -0.9085421409207677\n"
     ]
    }
   ],
   "source": [
    "# print the estimated MLEs\n",
    "print(\"Estimated MLE - alpha:\", alpha_mle) # True alpha: 2\n",
    "print(\"Estimated MLE - beta:\", beta_mle) # True beta: 3\n",
    "print(\"Estimated MLE - sigma:\", sigma_mle) # True sigma: 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SARvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
